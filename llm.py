import os
from dotenv import load_dotenv
from langchain_cohere import ChatCohere
from langchain.memory import ConversationBufferMemory
from langchain_google_genai import ChatGoogleGenerativeAI
# ConversationChain is deprecated; use ConversationBufferMemory instead.

# Load environment variables
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '.env'))
COHERE_API_KEY = os.getenv('COHERE_API_KEY')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

# Set up Cohere chat model
llm_cohere = ChatCohere(cohere_api_key=COHERE_API_KEY, model="command-r")
llm = ChatGoogleGenerativeAI(api_key=GOOGLE_API_KEY, model="gemini-1.5-flash")

# Set up conversation memory (buffer memory is now recommended for simple chat)
memory = ConversationBufferMemory(memory_key="history", return_messages=True)
# For now, we will just use llm.invoke(prompt) for summary generation.

import re

def enforce_exact_brief_format(summary: str) -> str:
    """
    Enforces the exact format and indentation as shown in the sample brief.
    - Preserves all newlines and indentation
    - Removes any excessive or missing whitespace
    - Ensures bullet points and sections are aligned as per the sample
    """
    # Remove leading/trailing whitespace and normalize newlines
    summary = summary.strip().replace('\r\n', '\n').replace('\r', '\n')
    # Remove double spaces and excessive blank lines
    summary = re.sub(r' +', ' ', summary)
    summary = re.sub(r'\n{3,}', '\n\n', summary)
    # Ensure each bullet starts with '- ✔️' or similar and proper indentation
    summary = re.sub(r'(?m)^- ?✔️', '- ✔️', summary)
    # Indent sub-bullets by two spaces
    summary = re.sub(r'(?m)^\s*- ', '  - ', summary)
    # Fix section headers to match the sample (no bold, just plain text)
    # Remove any markdown bold/italic
    summary = re.sub(r'\*\*(.*?)\*\*', r'\1', summary)
    summary = re.sub(r'__([^_]+)__', r'\1', summary)
    # Remove any leading 'Here is the morning brief...' duplicates
    summary = re.sub(r'^(Here is the morning brief.*?)\n+', r'\1\n', summary, flags=re.IGNORECASE)
    return summary

def format_llm_summary(summary: str) -> str:
    """
    Cleans and formats the LLM summary string as Markdown for better readability.
    - Uses larger section headers
    - Ensures bullet points and spacing
    - Highlights key numbers
    - Removes garbled or repeated text
    """
    # Remove any repeated or garbled text (e.g., numbers with letters in between)
    summary = re.sub(r'(\d)[,\s]+(\d)', r'\1,\2', summary)  # Fix comma placement
    summary = re.sub(r'([a-zA-Z])([0-9])', r'\1 \2', summary)  # Add space between letters and numbers
    summary = re.sub(r'([0-9])([a-zA-Z])', r'\1 \2', summary)
    summary = re.sub(r'(?<=\d)\s+a\s+c\s+r\s+o\s+s\s+s\s+', ' across ', summary, flags=re.IGNORECASE)
    summary = re.sub(r'(?<=\d)\s+o\s+n\s+t\s+h\s+e\s+i\s+r\s+p\s+u\s+r\s+c\s+h\s+a\s+s\s+e\s+s\s+', ' on their purchases, ', summary, flags=re.IGNORECASE)
    summary = re.sub(r'(?<=\d)\s+t\s+r\s+a\s+n\s+s\s+a\s+c\s+t\s+i\s+o\s+n\s+s\s+', ' transactions, ', summary, flags=re.IGNORECASE)
    summary = re.sub(r'(?<=\d)\s+f\s+o\s+l\s+l\s+o\s+w\s+e\s+d\s+c\s+l\s+o\s+s\s+e\s+l\s+y\s+b\s+y\s+', ' followed closely by ', summary, flags=re.IGNORECASE)


    # Remove bullet points and sub-bullets
    summary = re.sub(r'\n\s*- ', '\n', summary)
    summary = re.sub(r'  - ', '  ', summary)

    # Add spacing between sections
    summary = re.sub(r'(### [^\n]+)', r'\n\1\n', summary)
    # Bold all numbers for emphasis (e.g., 1234, 12.5, 1,234)
    summary = re.sub(r'(\b\d{1,3}(?:,\d{3})*(?:\.\d+)?\b)', r'**\1**', summary)
    # Remove excessive newlines
    summary = re.sub(r'\n{3,}', '\n\n', summary)
    summary = summary.strip()
    return summary

def summarize_db_output(db_output, user_message=None):
    """
    Passes the DB output to the Cohere chat model with a prompt to generate a user-friendly summary.
    Maintains session memory for ongoing conversations.
    Args:
        db_output (dict or str): The output from the DB query (dict recommended).
        user_message (str, optional): An optional user message for context.
    Returns:
        str: User-friendly summary generated by the LLM.
    """
    prompt = f"""
        You are an AI assistant that summarises daily retail store performance for the owner in a meaningful and actionable way.
           Input Data:
            {db_output}
        Task:
            Write a brief summary with the following structure:

        Summary:
        Start with 2-3 lines summarising how the store performed yesterday in simple words. Highlight if sales were good, average, or poor based on the sales amount and transactions.
        Include immediate attention items, such as products running low on stock or out of stock.

        Actions:
        List 2-3 immediate actions that the owner should take based on the summary.

        Tone:
        Professional, clear, and actionable. Avoid unnecessary adjectives. Highlight immediate actions like ordering low-stock products

        Give output as markdown
        """    
    if user_message:
        prompt += f"\nUser context: {user_message}\n"
    response = llm.invoke(prompt)
    formatted_response = format_llm_summary(str(response.content))
    action_items = get_action_items(formatted_response, user_message)
    raw= str(response.content)
    print("THis is the raw output")
    print(raw)
    action_items = get_action_items(raw, user_message)
    formatted_response = format_llm_summary(raw)
    return formatted_response, action_items

# def get_action_items(text, user_message=None):
#     import re
#     # Grab the Actions: block
#     # actions_pattern = re.compile(r"Actions?:\s*(.*?)(?:\n\s*\n|$)", re.DOTALL | re.IGNORECASE)
#     # match = actions_pattern.search(text)
#     # section = match.group(1).strip() if match else text

#     # # Match either numbered lines or hyphens, or plain lines
#     # action_lines = re.findall(
#     #     r"(?:^|\n)\s*(?:\d+\.\s*|\-\s*)(.+)", 
#     #     section
#     # )
#     # # Fallback: every non-blank line
#     # if not action_lines:
#     #     action_lines = [line.strip() for line in section.splitlines() if line.strip()]

#     # Build the bullet prompt for the button-generator LLM
#     #actions_for_prompt = "\n".join(f"- {line}" for line in action_lines)
#     prompt = f"""You are an AI assistant creating action buttons text from the following list of actions. 
#     Keep the action button text short and concise, 2-4 words each.
#     Actions List:
#     {text}
#     Task:
#     Create 2-3 action buttons text based on the above actions.
#     eg: ['action1', 'action2', 'action3']"""
    
#     if user_message:
#         prompt += f"\nUser context: {user_message}\n"
#     response = llm.invoke(prompt)
#     print("This is the LLM response")
#     print(response.content)
#     import ast
#     try:
#         action_items = ast.literal_eval(response.content)
#         print("this is after literal_eval")
#         print(action_items)
#     except Exception:
#         # Fallback: extract 2-3 short button texts from the first few action lines
#         action_items = []
#         for line in response.content.splitlines()[:3]:
#             # Take the first 5 words as a button text
#             btn = " ".join(line.split()[:5]).strip(':,.- ')
#             if btn:
#                 action_items.append(btn)
#                 print(action_items)
#     return action_items


def get_action_items(text, user_message=None):
    import re
    action_items = []  # Ensure always assigned
    # Grab the Actions: block
    # actions_pattern = re.compile(r"Actions?:\s*(.*?)(?:\n\s*\n|$)", re.DOTALL | re.IGNORECASE)
    # match = actions_pattern.search(text)
    # section = match.group(1).strip() if match else text

    # # Match either numbered lines or hyphens, or plain lines
    # action_lines = re.findall(
    #     r"(?:^|\n)\s*(?:\d+\.\s*|\-\s*)(.+)", 
    #     section
    # )
    # # Fallback: every non-blank line
    # if not action_lines:
    #     action_lines = [line.strip() for line in section.splitlines() if line.strip()]

    # Build the bullet prompt for the button-generator LLM
    #actions_for_prompt = "\n".join(f"- {line}" for line in action_lines)
    prompt = f"""You are an AI assistant creating action buttons text from the following list of actions. 
    Keep the action button text short and concise, 2-4 words each.
    Actions List:
    {text}
    Task:
    Create 2-3 action buttons text based on the above actions.
    eg: ['action1', 'action2', 'action3']"""
    
    if user_message:
        prompt += f"\nUser context: {user_message}\n"
    response = llm.invoke(prompt)
    print("This is the LLM response")
    print(response.content)
    import ast
    match = re.search(r"=\s*(\[[\s\S]*?\])", response.content)
    if match:
        list_str = match.group(1)  # Extract the list part
        try:
            action_items = ast.literal_eval(list_str)  # Safely parse the list
            return action_items
        except Exception:
            # Fallback: extract 2-3 short button texts from the first few action lines
            action_items = []
            for line in response.content.splitlines()[:3]:
                # Take the first 5 words as a button text
                btn = " ".join(line.split()[:5]).strip(':,.- ')
                if btn:
                    action_items.append(btn)
                    print(action_items)
    return action_items
